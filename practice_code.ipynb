{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea5603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# 1. (Recommended) If you set the key as an environment variable:\n",
    "#    The client finds it automatically.\n",
    "# client = genai.Client() \n",
    "\n",
    "# 2. (Explicitly passing the key for demonstration/testing)\n",
    "#    Replace 'YOUR_API_KEY_HERE' with your actual key (do not commit this to public code!)\n",
    "client = genai.Client(api_key=\"AIzaSyD-A3uBFC2jzddc0oKLdOWYHZ9-nIpebK4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92085af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A decorator is a function that takes another function as an argument to extend or modify its behavior without explicitly altering its source code.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"gemini-2.5-flash\" \n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=\"Explain what a decorator is in Python in one sentence.\"\n",
    ")\n",
    "\n",
    "# Print the model's text response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b9326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scenario 1: Frustrated Student (Confidence Builder) ---\n",
      "{\n",
      "    \"question\": \"Which of the following is the correct way to assign the integer value 5 to a variable named `count` in Python?\",\n",
      "    \"options\": [\n",
      "        \"count == 5\",\n",
      "        \"assign count = 5\",\n",
      "        \"count = 5\",\n",
      "        \"set count to 5\"\n",
      "    ],\n",
      "    \"answer\": \"count = 5\",\n",
      "    \"explanation\": \"You're doing great! In Python, we use the single equals sign (`=`) for assignment. This means we're telling the computer, 'Hey, store this value (5) inside this named container (`count`).' The double equals sign (`==`) is used for comparison, checking if two values are equal. Keep up the excellent work!\"\n",
      "}\n",
      "\n",
      "--- Scenario 2: Confident Student (Challenge Question) ---\n",
      "{\n",
      "    \"question\": \"Consider the following Python recursive function:def mysterious_sequence(n):    if n <= 0:        return 0    elif n == 1:        return 1    else:        return mysterious_sequence(n - 1) + mysterious_sequence(n - 2) + 1What will be the output of mysterious_sequence(4)?\",\n",
      "    \"options\": [\n",
      "        \"5\",\n",
      "        \"6\",\n",
      "        \"7\",\n",
      "        \"8\"\n",
      "    ],\n",
      "    \"answer\": \"7\",\n",
      "    \"explanation\": \"That's an excellent challenge, and it's clear you're ready for it! Let's break down `mysterious_sequence(4)` step by step:mysterious_sequence(0) returns 0 (base case)mysterious_sequence(1) returns 1 (base case)mysterious_sequence(2) = mysterious_sequence(1) + mysterious_sequence(0) + 1= 1 + 0 + 1= 2mysterious_sequence(3) = mysterious_sequence(2) + mysterious_sequence(1) + 1= 2 + 1 + 1= 4mysterious_sequence(4) = mysterious_sequence(3) + mysterious_sequence(2) + 1= 4 + 2 + 1= 7Great job for tackling such a nuanced recursive problem! Your confidence is well-placed, and tracing these kinds of functions shows a strong grasp of recursion.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# --- 1. Setup the Gemini Client ---\n",
    "\n",
    "# Initialize the client. It automatically looks for the GEMINI_API_KEY \n",
    "# or GOOGLE_API_KEY in your environment variables.\n",
    "try:\n",
    "    client = genai.Client(api_key=\"AIzaSyD-A3uBFC2jzddc0oKLdOWYHZ9-nIpebK4\")\n",
    "except Exception as e:\n",
    "    print(\"Error initializing Gemini client. Make sure your API key is set.\")\n",
    "    print(e)\n",
    "    # Exit or handle the error gracefully in a real application\n",
    "    client = None\n",
    "\n",
    "# --- 2. Define the Required JSON Output Schema ---\n",
    "\n",
    "# We use the Schema to force the model to return a structured dictionary.\n",
    "QUIZ_SCHEMA = types.Schema(\n",
    "    type=types.Type.OBJECT,\n",
    "    properties={\n",
    "        \"question\": types.Schema(\n",
    "            type=types.Type.STRING, \n",
    "            description=\"The programming question text.\"\n",
    "        ),\n",
    "        \"options\": types.Schema(\n",
    "            type=types.Type.ARRAY, \n",
    "            items=types.Schema(type=types.Type.STRING), \n",
    "            description=\"A list of exactly four possible answers.\"\n",
    "        ),\n",
    "        \"answer\": types.Schema(\n",
    "            type=types.Type.STRING, \n",
    "            description=\"The correct answer, which must exactly match one of the strings in the options list.\"\n",
    "        ),\n",
    "        \"explanation\": types.Schema(\n",
    "            type=types.Type.STRING, \n",
    "            description=\"A clear, empathetic, and motivating explanation for why the answer is correct.\"\n",
    "        )\n",
    "    },\n",
    "    required=[\"question\", \"options\", \"answer\", \"explanation\"]\n",
    ")\n",
    "\n",
    "def generate_adaptive_quiz(topic: str, difficulty: str, emotional_status: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generates a structured, adaptive quiz question using the Gemini API.\n",
    "\n",
    "    Args:\n",
    "        topic (str): The programming concept (e.g., 'Variables', 'Loops').\n",
    "        difficulty (str): The challenge level ('Easy', 'Medium', 'Hard').\n",
    "        emotional_status (str): The student's inferred state ('Frustrated', 'Confident').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the question, options, answer, and explanation.\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return {\"error\": \"Gemini client not initialized.\"}\n",
    "\n",
    "    # --- 3. Construct the Adaptive Prompt ---\n",
    "    \n",
    "    # The system instruction sets the persona and primary task constraint.\n",
    "    system_instruction = (\n",
    "        \"You are an empathetic, world-class programming tutor. \"\n",
    "        \"Your task is to generate a multiple-choice quiz question with exactly 4 options. \"\n",
    "        \"The question must be tailored to the student's specified emotional state and difficulty level. \"\n",
    "        \"If the student is 'Frustrated', generate a simple, confidence-building question. \"\n",
    "        \"If the student is 'Confident', generate a tricky question involving edge cases or subtle syntax details.\"\n",
    "    )\n",
    "\n",
    "    # The user prompt contains the specific context variables.\n",
    "    user_prompt = f\"\"\"\n",
    "    Generate a quiz question based on the following context:\n",
    "    1. Topic: {topic}\n",
    "    2. Difficulty: {difficulty}\n",
    "    3. Student Emotional Status: {emotional_status}\n",
    "    \n",
    "    The output must be returned strictly in JSON format matching the defined schema.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 4. Call the Gemini API with Structured Output ---\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.5-flash',\n",
    "            contents=user_prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=system_instruction,\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=QUIZ_SCHEMA,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # The response.text will be a valid JSON string due to the config.\n",
    "        # We parse it into a Python dictionary.\n",
    "        return json.loads(response.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"API call failed: {e}\"}\n",
    "\n",
    "# --- 5. Example Usage ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error initializing Gemini client. Make sure your API key is set.\n",
      "Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.\n",
      "--- Scenario 1: Frustrated Student (Confidence Builder) ---\n",
      "{\n",
      "    \"error\": \"Gemini client not initialized.\"\n",
      "}\n",
      "\n",
      "--- Scenario 2: Confident Student (Challenge Question) ---\n",
      "{\n",
      "    \"error\": \"Gemini client not initialized.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "import os\n",
    "from evaluate import evaluate_emotional_status, evaluate_difficulty\n",
    "def take_quiz(topic_key):\n",
    "    \"\"\"\n",
    "    Displays a quiz question for the given topic key, generating it adaptively\n",
    "    based on the student's state inferred from the backend.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. EVALUATE CURRENT STUDENT STATE\n",
    "    # This runs the Bayesian/RL logic\n",
    "    current_emotion = evaluate_emotional_status(topic_key)\n",
    "    current_difficulty = evaluate_difficulty(topic_key)\n",
    "\n",
    "    st.header(f\"Quiz: {topic_key.capitalize()} Mastery Check\")\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Inform the tutor/user of the inferred state\n",
    "    st.info(f\"üí° **Tutor State:** Inferred Emotion: **{current_emotion}** | Target Difficulty: **{current_difficulty}**\")\n",
    "    \n",
    "    # 2. GENERATE QUESTION (Only if not already generated/cached)\n",
    "    quiz_key = f\"quiz_data_{topic_key}\"\n",
    "    \n",
    "    # Only call the LLM if we haven't already generated the question for this topic\n",
    "    if st.session_state['current_quiz'] is None or st.session_state['current_quiz']['topic'] != topic_key:\n",
    "        with st.spinner(f\"Generating an adaptive '{current_emotion}' question on '{topic_key}'...\"):\n",
    "            \n",
    "            # --- CALL THE GEMINI ADAPTIVE FUNCTION ---\n",
    "            # This function returns a structured dictionary (question, options, answer, explanation)\n",
    "            generated_data = generate_adaptive_quiz(\n",
    "                topic=topic_key,\n",
    "                difficulty=current_difficulty,\n",
    "                emotional_status=current_emotion\n",
    "            )\n",
    "            \n",
    "            # Store the generated data and the topic it belongs to\n",
    "            st.session_state['current_quiz'] = generated_data\n",
    "            st.session_state['current_quiz']['topic'] = topic_key\n",
    "            st.session_state[quiz_key] = generated_data\n",
    "\n",
    "    # Retrieve the question data from the session state\n",
    "    quiz_data = st.session_state['current_quiz']\n",
    "    \n",
    "    if 'error' in quiz_data:\n",
    "        st.error(f\"Failed to load quiz: {quiz_data['error']}\")\n",
    "        return\n",
    "\n",
    "    # 3. DISPLAY THE QUESTION\n",
    "    question = quiz_data[\"question\"]\n",
    "    options = quiz_data[\"options\"]\n",
    "    answer = quiz_data[\"answer\"]\n",
    "    explanation = quiz_data[\"explanation\"]\n",
    "\n",
    "    st.subheader(question)\n",
    "    \n",
    "    # Create radio buttons for options. The key is vital for Streamlit to track state.\n",
    "    user_choice = st.radio(\"Select your answer:\", options, key=f\"user_choice_{topic_key}\")\n",
    "    \n",
    "    # --- 4. EVALUATE SUBMISSION ---\n",
    "    \n",
    "    if st.button(\"Submit Answer\"):\n",
    "        # The logic below simulates the core interaction feedback loop\n",
    "        if user_choice == answer:\n",
    "            st.success(\"‚úÖ Correct! Excellent work. You're ready for a challenge!\")\n",
    "            # In a real app, this is where you'd update the student's mastery level in your Bayesian/RL system\n",
    "        else:\n",
    "            st.error(f\"‚ùå Incorrect. The correct answer was **{answer}**.\")\n",
    "            st.warning(\"Let's review this concept. I've adjusted the next lesson plan.\")\n",
    "            # In a real app, this is where you'd update the student's emotional state to 'Frustrated' or 'Mildly Confused'\n",
    "        \n",
    "        st.info(f\"**Explanation:** {explanation}\")\n",
    "        \n",
    "        # Reset the quiz cache so a new question is generated next time\n",
    "        st.session_state['current_quiz'] = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
